---
permalink: /research/
title: Research interests
header:
  overlay_image: ../images/dst2_background.png
  overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
---

Bertrand Russell is known for his observation that the fundamental laws of physics contain no notion of cause and effect. The laws describe only correlations between physical quantities. A response is that this leaves causal relationships something that we project on to the world in order to make sense of our place within it and to control it. On this view causality is closely tied to our ability to see ourselves as agents in the world, free to act and to intervene on systems and to learn the effect. Statisticians, and some philosophers, take this idea seriously -- a causal understanding of a system is an understanding of the effect of one's actions or interventions on it.

Human causal reasoning is in many ways more sophisticated than other animals' causal reasoning abilities. How is it that we acquire these causal relations? Further, causal understandings of an environment are often lacking in contemporary AI agents trained through reinforcement learning and/or deep learning. What, exactly, are the limits of these methods to learn human-like causal models and reasoning abilities? What additional components may need to be 'innately' specified? Answering these questions requires both carefully characterizing the causal model building capabilities of agents trained through reinforcement learning, and understanding the mechanisms humans use for causal learning.
